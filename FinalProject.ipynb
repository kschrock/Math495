{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Math 495 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <span style=\"color: purple;\">Kordell Schrock & Clark Reimers</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all dependencies installed now\n"
     ]
    }
   ],
   "source": [
    "# Installs necessary packages for you\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "required = {'category_encoders', 'sklearn'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "    print(\"all dependencies installed now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
       "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
       "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
       "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
       "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
       "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "1           NaN        NaN         NaN       NaN    NaN  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "4           NaN        NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"GameSales2016.csv\") #import dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <span style=\"color: purple;\">Clean the Data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6824 entries, 0 to 16706\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Name             6824 non-null   object \n",
      " 1   Platform         6824 non-null   object \n",
      " 2   Year_of_Release  6824 non-null   float64\n",
      " 3   Genre            6824 non-null   object \n",
      " 4   Publisher        6824 non-null   object \n",
      " 5   NA_Sales         6824 non-null   float64\n",
      " 6   EU_Sales         6824 non-null   float64\n",
      " 7   JP_Sales         6824 non-null   float64\n",
      " 8   Other_Sales      6824 non-null   float64\n",
      " 9   Global_Sales     6824 non-null   float64\n",
      " 10  Critic_Score     6824 non-null   float64\n",
      " 11  Critic_Count     6824 non-null   float64\n",
      " 12  User_Score       6824 non-null   object \n",
      " 13  User_Count       6824 non-null   float64\n",
      " 14  Developer        6824 non-null   object \n",
      " 15  Rating           6824 non-null   float64\n",
      "dtypes: float64(10), object(6)\n",
      "memory usage: 906.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna() #remove NA rows\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't touch my shit please\n",
    "#begin\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import sklearn as sklearn\n",
    "\n",
    "\n",
    "df2 = pd.read_csv(\"GameSales2016.csv\") #import dataset\n",
    "\n",
    "#cleaning up variables\n",
    "df2 = df2.replace(to_replace = '\\n',value='',regex=True)\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.select_dtypes(exclude=['object'])\n",
    "\n",
    "#Reset indeces\n",
    "df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.sort_values(by=['Global_Sales'],ascending=False)\n",
    "#for i in df2.columns:\n",
    "#    sns.relplot(y=i,x='Global_Sales',data=df2)\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the graphs, I think that the best variables to use are\n",
    "#maybe publisher, genre\n",
    "#probably Critic_Score, User_Score, User_Count, Developer, Rating\n",
    "#definitely (so long as it is in scope) NA_sales, EU_Sales, Other_Sales, JP_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingToNumber = {'RP':0,'AO':1,'E10+':2,'T':3,'M':4,'E':5}\n",
    "#df2['Rating'] = df2['Rating'].map(ratingToNumber)\n",
    "\n",
    "#tmplist = df2[['Critic_Score','User_Score','User_Count','Rating','NA_Sales',\n",
    "#                   'EU_Sales','Other_Sales','JP_Sales']].copy()\n",
    "\n",
    "feature_cols = df2.columns.values.tolist()\n",
    "feature_cols.remove('Global_Sales')\n",
    "tmplist = df2[feature_cols]\n",
    "\n",
    "\n",
    "y=df2.Global_Sales\n",
    "tmp = []\n",
    "for i in tmplist:\n",
    "    X=pd.DataFrame(np.c_[df2[i]],columns=[i])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=9)\n",
    "    lin_reg_mod = LinearRegression()\n",
    "    lin_reg_mod.fit(X_train, y_train)\n",
    "    pred = lin_reg_mod.predict(X_test)\n",
    "    test_set_r2 = r2_score(y_test, pred)\n",
    "    tmp.append(tuple((i,test_set_r2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsquared = 0.9999844680738513\n",
      "MAE is: 0.003670608744158502\n",
      "MSE is: 3.559776273788779e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "##sort tuples in descending order to find the highest rsquared variables\n",
    "tmp.sort(key = lambda x:x[1],reverse=True)\n",
    "#print(\"vals\",tmp)\n",
    "\n",
    "##Now I want to run it again but using the first 4 largest r squared values (I determined 4 was the best through trial and error)\n",
    "##They are curbweight, enginesize, carwidth, and horsepower, as seen in the tuple print out\n",
    "##curbweight = int64, enginesize = int64, carwidth = float64, horsepower = int64\n",
    "#print(df.dtypes)\n",
    "\n",
    "X=pd.DataFrame(np.c_[df2[tmp[0][0]],df2[tmp[1][0]],df2[tmp[2][0]],df2[tmp[3][0]]],\n",
    "               columns=[tmp[0][0],tmp[1][0],tmp[2][0],tmp[3][0]])\n",
    "y=df2.Global_Sales\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=9)\n",
    "lin_reg_mod = LinearRegression()\n",
    "lin_reg_mod.fit(X_train, y_train)\n",
    "pred = lin_reg_mod.predict(X_test)\n",
    "test_set_r2 = r2_score(y_test, pred)\n",
    "print('rsquared =',test_set_r2)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print('MAE is:',mae)\n",
    "mse = mean_squared_error(y_test, pred)\n",
    "print('MSE is:',mse)\n",
    "#accuracy\n",
    "#print(\"Accuracy:\",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "#print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual values:\n",
      "      predicted  actual\n",
      "0     0.240245   28.32\n",
      "1     0.010271   21.79\n",
      "2     1.350160   15.29\n",
      "3     1.150174   13.79\n",
      "4     0.380237   13.47\n",
      "..         ...     ...\n",
      "583   0.180255    0.61\n",
      "584   6.399720    0.61\n",
      "585   0.320244    0.61\n",
      "586   0.730220    0.61\n",
      "587   0.130261    0.61\n",
      "\n",
      "[588 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "##You will have to report the summary of the model, predictions and actual values as two columns in a dataframe\n",
    "summary = pd.DataFrame()\n",
    "summary['predicted'] = pred\n",
    "summary['actual'] = y_test\n",
    "summary = summary.dropna()\n",
    "##Reset indeces\n",
    "summary.reset_index(drop=True, inplace=True)\n",
    "print(\"\\nPredictions vs Actual values:\\n\",summary)\n",
    "#End "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'User_Score' rows with 'tbd' values to be dropped\n",
    "df = df.drop(df[df.User_Score == 'tbd'].index)\n",
    "# Replace old videogame rating convention \"K-A\" with \"E\"\n",
    "df['Rating']=df['Rating'].replace(['K-A'], 'E')\n",
    "#Convert 'Year_of_Release' from float to integer\n",
    "df['Year_of_Release']=df['Year_of_Release'].astype(int)\n",
    "#Convert 'User_Score' from object to float\n",
    "df['User_Score']=10*df['User_Score'].astype(float)\n",
    "#rename column\n",
    "df = df.rename(columns={\"Year_of_Release\": \"Year\"})\n",
    "#calculate how old a Video Game is\n",
    "df[\"Age\"] = 2018 - df[\"Year\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "noObjects = df.select_dtypes(exclude=['object']) #remove objects\n",
    "Xcols= noObjects.drop([], axis=1)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"features\"] = Xcols.columns\n",
    "vif[\"vif_Factor\"] = [variance_inflation_factor(Xcols.values, i) for i in range(Xcols.shape[1])]\n",
    "print(vif) #vif Factor is helpful to find columns to remove since they are not good independent variables\n",
    "#VIF factor under 10 is good for independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True, cmap=\"YlGnBu\") #print the heat map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = df.dropna(subset=[\"User_Score\", \"Critic_Score\", \"Rating\"])\n",
    "scored.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "numeric_subset = scored.select_dtypes(\"number\").drop(columns=[\"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\", \"Year\"])\n",
    "\n",
    "# Select the categorical column\n",
    "categorical_subset = scored[[\"Platform\", \"Genre\", \"Rating\"]]\n",
    "\n",
    "# One hot encode\n",
    "encoder = ce.one_hot.OneHotEncoder()\n",
    "categorical_subset = encoder.fit_transform(categorical_subset)\n",
    "\n",
    "# Join the two dataframes using concat\n",
    "# Make sure to use axis = 1 to perform a column bind\n",
    "features = pd.concat([numeric_subset, categorical_subset], axis = 1)\n",
    "\n",
    "# Find correlations with the score \n",
    "correlations = features.corr()[\"Global_Sales\"].dropna().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "basic_target = pd.Series(features[\"Global_Sales\"])\n",
    "basic_features = features.drop(columns=\"Global_Sales\")\n",
    "features_train, features_test, target_train, target_test = train_test_split(basic_features, basic_target, \n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42)\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model):\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    # Make predictions and evalute\n",
    "    model_pred = model.predict(features_test)\n",
    "    model_mae = mae(target_test, model_pred)\n",
    "    \n",
    "    # Return the performance metric\n",
    "    return model_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return np.average(abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr_mae = fit_and_evaluate(lr)\n",
    "\n",
    "print(\"Linear Regression Performance on the test set: MAE = {:.04f}\".format(lr_mae))\n",
    "# Loss function to be optimized\n",
    "loss = [\"ls\", \"lad\", \"huber\"]\n",
    "\n",
    "# Maximum depth of each tree\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "\n",
    "# Minimum number of samples per leaf\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "# Minimum number of samples to split a node\n",
    "min_samples_split = [2, 4, 6, 10]\n",
    "\n",
    "# Maximum number of features to consider for making splits\n",
    "max_features = [\"auto\", \"sqrt\", \"log2\", None]\n",
    "\n",
    "hyperparameter_grid = {\"loss\": loss,\n",
    "                       \"max_depth\": max_depth,\n",
    "                       \"min_samples_leaf\": min_samples_leaf,\n",
    "                       \"min_samples_split\": min_samples_split,\n",
    "                       \"max_features\": max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "basic_model = GradientBoostingRegressor(random_state = 42)\n",
    "\n",
    "random_cv = RandomizedSearchCV(estimator=basic_model,\n",
    "                               param_distributions=hyperparameter_grid,\n",
    "                               cv=4, n_iter=20, \n",
    "                               scoring=\"neg_mean_absolute_error\",\n",
    "                               n_jobs=-1, verbose=1, \n",
    "                               return_train_score=True,\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results = pd.DataFrame(random_cv.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n",
    "random_results.head(10)[[\"mean_test_score\", \"param_loss\",\n",
    "                         \"param_max_depth\", \"param_min_samples_leaf\", \"param_min_samples_split\",\n",
    "                         \"param_max_features\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "trees_grid = {\"n_estimators\": [50, 100, 150, 200, 250, 300]}\n",
    "\n",
    "basic_model = random_cv.best_estimator_\n",
    "grid_search = GridSearchCV(estimator=basic_model, param_grid=trees_grid, cv=4, \n",
    "                           scoring=\"neg_mean_absolute_error\", verbose=1,\n",
    "                           n_jobs=-1, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(features_train, target_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_final_model = grid_search.best_estimator_\n",
    "#basic_final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_final_pred = basic_final_model.predict(features_test)\n",
    "#basic_final_mae = mae(target_test, basic_final_pred)\n",
    "#print(\"Final model performance on the test set: MAE = {:.04f}.\".format(basic_final_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "plt.plot(results[\"param_n_estimators\"], -1 * results[\"mean_test_score\"], label = \"Testing Error\")\n",
    "plt.plot(results[\"param_n_estimators\"], -1 * results[\"mean_train_score\"], label = \"Training Error\")\n",
    "plt.xlabel(\"Number of Trees\"); plt.ylabel(\"Mean Abosolute Error\"); plt.legend();\n",
    "plt.title(\"Performance vs Number of Trees\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RandomForestRegressor = RandomForestRegressor(n_estimators=15,criterion='mse',random_state=25)\n",
    "#using the Random Forest Regressor \n",
    "# Train the model\n",
    "    #model.fit(features_train, target_train)\n",
    "  # Make predictions and evalute\n",
    "    #model_pred = model.predict(features_test)\n",
    "RandomForestRegressor.fit(features_train,target_train) # fit the model\n",
    "RandomForestRegressor_pred = RandomForestRegressor.predict(features_test) #get the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "score = r2_score(target_test,RandomForestRegressor_pred) #get the r squared value\n",
    "print('Model: Random Forest')\n",
    "print(\"r2score: \" , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualvspredicted= pd.DataFrame()\n",
    "actualvspredicted['_Actual_'] = target_test\n",
    "actualvspredicted['_Predicted_'] = RandomForestRegressor_pred\n",
    "print(actualvspredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (sns.kdeplot(RandomForestRegressor_pred, label = \"Predictions\").set(xlim=(0,3)))\n",
    "sns.kdeplot(target_test, label = \"Test\")\n",
    "sns.kdeplot(target_train, label = \"Train\")\n",
    "#plt.set_xlim([0,2])\n",
    "plt.xlabel(\"Global Sales\"); plt.ylabel(\"Density\");\n",
    "plt.title(\"Test, Train Values and Predictions\");\n",
    "\n",
    "plt.show(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "est = sm.OLS(target_train,features_train).fit() #fit the model the data\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
